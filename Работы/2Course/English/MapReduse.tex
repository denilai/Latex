\documentclass[a4paper,12pt]{article}
%\usepackage[top=25mm,bottom=20mm,left=35mm,right=20mm]{geometry} % Простой способ задавать поля

\author{Jeffrey Dean and Sanjay Ghemawat}
\title{MapReduce: Simplified Data Processing on Large Clusters}

\begin{document}
	
	\maketitle
	\section{Abstract}
	
	MapReduce is a programming model and an associated implementation for processing and generating large
	data sets. Users specify a map function that processes a
	key/value pair to generate a set of intermediate key/value
	pairs, and a reduce function that merges all intermediate
	values associated with the same intermediate key. Many
	real world tasks are expressible in this model, as shown
	in the paper.
	
	Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the
	details of partitioning the input data, scheduling the program’s execution across a set of machines, handling machine failures, and managing the required inter-machine
	communication. This allows programmers without any
	experience with parallel and distributed systems to easily utilize the resources of a large distributed system.
	
	Our implementation of MapReduce runs on a large
	cluster of commodity machines and is highly scalable:
	a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers
	find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google’s clusters
	every day.
		\section{Introduction}
	Over the past five years, the authors and many others at
	Google have implemented hundreds of special-purpose
	computations that process large amounts of raw data,
	such as crawled documents, web request logs, etc., to
	compute various kinds of derived data, such as inverted
	indices, various representations of the graph structure
	of web documents, summaries of the number of pages
	crawled per host, the set of most frequent queries in a
	given day, etc. Most such computations are conceptually straightforward. However, the input data is usually
	large and the computations have to be distributed across
	hundreds or thousands of machines in order to finish in
	a reasonable amount of time. The issues of how to parallelize the computation, distribute the data, and handle
	failures conspire to obscure the original simple computation with large amounts of complex code to deal with
	these issues.
	
	As a reaction to this complexity, we designed a new
	abstraction that allows us to express the simple computations we were trying to perform but hides the messy details of parallelization, fault-tolerance, data distribution
	and load balancing in a library. Our abstraction is inspired by the map and reduce primitives present in Lisp
	and many other functional languages. We realized that
	most of our computations involved applying a map operation to each logical “record” in our input in order to
	compute a set of intermediate key/value pairs, and then
	applying a reduce operation to all the values that shared
	the same key, in order to combine the derived data appropriately. Our use of a functional model with userspecified map and reduce operations allows us to parallelize large computations easily and to use re-execution
	as the primary mechanism for fault tolerance.
	
	The major contributions of this work are a simple and
	powerful interface that enables automatic parallelization
	and distribution of large-scale computations, combined
	with an implementation of this interface that achieves
	high performance on large clusters of commodity PCs.
	Section 2 describes the basic programming model and
	gives several examples. Section 3 describes an implementation of the MapReduce interface tailored towards
	our cluster-based computing environment. Section 4 describes several refinements of the programming model
	that we have found useful. Section 5 has performance
	measurements of our implementation for a variety of
	tasks. Section 6 explores the use of MapReduce within
	Google including our experiences in using it as the basis for a rewrite of our production indexing system. Section 7 discusses related and future work.
	
\end{document}