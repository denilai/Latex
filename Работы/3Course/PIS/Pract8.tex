\documentclass[a4paper,14pt]{extarticle}

\newcommand{\stend}{\textbf{Wb-demo-kit v.2}}

% Путь до папки с общими шаблонами
\newcommand{\pathToCommonFolder}{/home/denilai/Documents/repos/latex/Common}

% Название работы в титуле
\newcommand{\workname}{Отчет по практической работе №8}
% Название дисциплины в титуле
\newcommand{\discipline}{Проектирование информационных систем}
% Название кафедры в титуле
\newcommand{\kafedra}{Кафедра инструментального и прикладного программного обеспечения}
% Тема работы в титуле
\newcommand{\theme}{Создание полного текстового описания, глоссария и расчет параметров проектируемой информационной системы}
% Должность преподавателя в титуле
\newcommand{\rang}{ассистент}

% ФИО студента в титуле
\newcommand{\studentfio}{К.~Ю.~Денисов}%\\Д.~Н.~Федосеев\\А.~М.~Сосунов}\\%К.~Ю.~Денисов\\%И.~А.~Кремнев
% ФИО преподавателя в титуле
\newcommand{\teacherfio}{А.~А.~Русляков}


\usepackage{tabularx}
\usepackage{lastpage}


\usepackage{booktabs}
\newcolumntype{b}{X}
\newcolumntype{s}{>{\hsize=.5\hsize}X}
\newcommand{\heading}[1]{\multicolumn{1}{|c|}{\textbf{#1}}}

% установка размера шрифта для всего документа
%\fontsize{20pt}{18pt}\selectfont
\usepackage{extsizes} % Возможность сделать 14-й шрифт

% Вставка заготовки преамбулы
\input{\pathToCommonFolder/ruspreamble}

\author{Кирилл Денисов}
\title{Лабораторная работа №1}
\date{\today}

\setcounter{withouttheme}{0}
\setcounter{withoutsubmissiondate}{1}

%если нужна тема работы в отчете, то указать в скобках что-либо, иначе оаставить пустым
%\renewcommand{\withouttheme}{}
%если нужна дата представления отчета, то указать в скобках что-либо
%\renewcommand{\withoutsubmissiondate}{1}

% установка полуторного интервала
% \usepackage{setspace}  
% \onehalfspacing

% использовать Times New Roman
\renewcommand{\rmdefault}{ftm}


\newcommand{\tb}{ThingsBoard~}

\begin{document}
	\thispagestyle{empty}
	% Вставка первого титульного листа
	% Есть две версии титульного листа - одиночный (titul) и групповой (titulAll)
	\input{\pathToCommonFolder/titul}
	\newpage
	%\tableofcontents
	\newpage
	%\listoftables
	
\normalsize

\section{Описание ЭСЕ}

Элементарная семантическая единица (ЭСЕ) --- неделимая единица
информации, использующаяся в ИС. ЭСЕ представляет собой завершенную
контекстную конструкцию, вызываемую в результате поиска по различным
атрибутам или в результате тех или иных команд в виде отклика или отчета. В случае исследования настоящей системы за элементарную семантическую единицу была выбрана одна из характеристик поиска, а именно, количество файлов, удовлетворяющим пользовательским критериям поиска. В нашем примере эта величина меняется случайным
образом в пределах от 0 до 49999 [файлов].


\subsection{Наполнение системы}

Проектируемая информационная система <<Электронный сборник лабораторных работ>> может быть наполнена
практически любым количеством элементов базы данных. Их количество
ограничиваются только параметрами сервера.

В рамках данной практической работы система была наполнена 50000 ЭСЕ. Было проведено сто экспериментов, в ходе которых стало известно количество файлов, удовлетворяющих пользовательским параметрам, заданным в модуле поиска Подсистемы хранения ИС <<Электронный сборник лабораторных работ>>. Список результатов измерений приведен в приложении 1.


\subsection{Математические расчеты}
Для дальнейшего исследования проектируемой ИС необходимо
рассчитать вероятности, с которыми ЭСЕ принимает то или иное значение.
Для оценки этих вероятностей было принято решение разбить весь диапазон
значений на 10 дискретных величин с шагом в 5000. Расчеты вероятности ведутся с
помощью следующей формулы  \ref{math:prob}.
\begin{align}
	P(\xi)=\frac{n}N \label{math:prob}
\end{align}
В данной формуле $n$ --- благоприятное число исходов (в данном
случае число найденных файлов, попавших в данный диапазон), а $N$ --- общее число исходов. 

В таблице \ref{tab:probs} приведены возможные значения, принимаемые ЭСЕ и их вероятности.

\begin{table}[h!]
	\centering
	\caption{Ряд распределения}
	\begin{tabular}{|c|c|c|}
		\hline
	№ &	$x_i$ & $P(x)$ \\ \hline\hline
	1 &	2499.50 & 150.15 \\ \hline
	2 &		7499.50 & 100.10 \\ \hline
	3 &		12499.50 & 80.08 \\ \hline
	4 &		17499.50 & 90.09 \\ \hline
	5 &		22499.50 & 110.11 \\ \hline
	6 &		27499.50 & 130.13 \\ \hline
	7 &		32499.50 & 100.10 \\ \hline
	8 &		37499.50 & 90.09 \\ \hline
	9 &		42499.50 & 60.06 \\ \hline
	10 &		47499.50 & 90.09 \\ \hline
	\end{tabular}
	\label{tab:probs}
\end{table}

\subsubsection{Расчет математического ожидания информационного блока системы}
Математическим ожиданием случайной величины называется сумма
произведений всех возможных значений случайной величины на вероятности
этих значений. 

Рассчитаем математическое ожидание для нашей системы, взяв
за случайную величину число файлов. Расчёт математического
ожидания информационного блока на примере 10 записей:

\begin{align}
M_{x_{i}} = \sum_{i=0}^{n}\left[p_i \cdot x_i\right] \label{math:expectation}
\end{align}
Используя данные, полученные в таблице \ref{tab:probs}, получаем:

$M(10) = 23199.50$ файлов, следовательно, наиболее вероятное
количество файлов в ответе на запрос находится в районе $23199.50$ [файлов].

\subsubsection{Расчет дисперсии информационного блока системы}

Рассчитаем дисперсию информационного блока системы по формуле \ref{math:dispers}.

\begin{align}
	D_{x_i}=\sum_{i=0}^{n}\left[p_i \cdot \left(x_i\right)^2 \right] - \left[\sum_{i=0}^{n} \left(p_i \cdot x_i\right) \right]^2
	\label{math:dispers}
\end{align}

Используя данные, полученные в таблице \ref{tab:probs}, получаем:

$D(10) = 206010000\mbox{ }файлов^2$

\subsubsection{Расчет среднеквадратического отклонения}

Рассчитаем среднеквадратическое отклонение по формуле \ref{math:square}.
\begin{align}
	\sigma x_i= \sqrt{Dx_i} = \sqrt{206010000} = 14353.05\mbox{ файлов}	
	\label{math:square}
\end{align}

\subsubsection{Расчет энтропии системы}

Информационная энтропия --- мера неопределённости некоторой системы (в статистической физике или теории информации), в частности, непредсказуемость появления какого-либо символа первичного алфавита. В последнем случае при отсутствии информационных потерь энтропия численно равна количеству информации на символ передаваемого сообщения

Вычислим энтропию системы по формуле 
\begin{align}
	H(x) = - \sum_{i=1}^{n}\left[p_i \cdot \log_ap_i\right]
\end{align}

За основание логарифма a возьмем двоичную систему счисления (формула Шеннона). Энтропия фрагмента информационного наполнения в размере 10 ЭСЕ:
Используя данные, полученные в таблице \ref{tab:probs}, получаем:
$H(10) = 3.28 $ бит.

\newpage
\subsection{РЕЗУЛЬТАТЫ РАСЧЕТОВ}

В данной главе был осуществлен расчет основных характеристик
проектируемой ИС, и получены следующие результаты:

\begin{table}[h!]
	\centering
	\caption{Параметры проектируемой ИС}
	\begin{tabular}{|p{0.6\linewidth}|p{0.4\linewidth}|}
		\hline
		Математическое ожидание информационного блока & $M(10) = 23199.50$ файлов\\\hline
		Допустимый разброс значений смысловых
		 информационных блоков (дисперсия) & $D(10) = 206010000\mbox{ }файлов^2$ \\\hline
		 Среднеквадратичное отклонение & $\sigma x_i=14353.05\mbox{ файлов}$	\\\hline
		  Энтропия информационного наполнения & $H(10) = 3.28 $ бит \\\hline
	\end{tabular}
\end{table}

Приведем таблицу с исходными сгенерированными данными (см. таблицу \ref{tab:source}).
\begin{table}[h!]
	\small
	\caption{Исходные значения}
	\centering
	\begin{tabular}{|r|r|r|r|r|r|r|r|}
		\hline
		\multicolumn{1}{|l|}{№} & \multicolumn{1}{l|}{Значение} & \multicolumn{1}{l|}{№} & \multicolumn{1}{l|}{Значение} & \multicolumn{1}{l|}{№} & \multicolumn{1}{l|}{Значение} & \multicolumn{1}{l|}{№} & \multicolumn{1}{l|}{Значение} \\ \hline
		1 & 19956 & 26 & 1983 & 51 & 3986 & 76 & 47044 \\ \hline
		2 & 30937 & 27 & 26452 & 52 & 20469 & 77 & 26520 \\ \hline
		3 & 49379 & 28 & 899 & 53 & 14592 & 78 & 35967 \\ \hline
		4 & 32802 & 29 & 41888 & 54 & 1352 & 79 & 21749 \\ \hline
		5 & 3998 & 30 & 8182 & 55 & 32704 & 80 & 18295 \\ \hline
		6 & 31012 & 31 & 2176 & 56 & 40990 & 81 & 21813 \\ \hline
		7 & 38782 & 32 & 28627 & 57 & 29975 & 82 & 13467 \\ \hline
		8 & 15895 & 33 & 25433 & 58 & 10325 & 83 & 23783 \\ \hline
		9 & 27847 & 34 & 9457 & 59 & 3700 & 84 & 32821 \\ \hline
		10 & 35964 & 35 & 2373 & 60 & 24083 & 85 & 17607 \\ \hline
		11 & 3827 & 36 & 10010 & 61 & 33412 & 86 & 36274 \\ \hline
		12 & 24247 & 37 & 48230 & 62 & 43067 & 87 & 10648 \\ \hline
		13 & 39557 & 38 & 26061 & 63 & 49735 & 88 & 19679 \\ \hline
		14 & 2321 & 39 & 5810 & 64 & 40199 & 89 & 49114 \\ \hline
		15 & 29616 & 40 & 25460 & 65 & 20796 & 90 & 43305 \\ \hline
		16 & 24485 & 41 & 30058 & 66 & 27099 & 91 & 21310 \\ \hline
		17 & 46153 & 42 & 859 & 67 & 36430 & 92 & 31711 \\ \hline
		18 & 35865 & 43 & 46295 & 68 & 18874 & 93 & 18424 \\ \hline
		19 & 44427 & 44 & 1274 & 69 & 6761 & 94 & 6493 \\ \hline
		20 & 26134 & 45 & 37563 & 70 & 8725 & 95 & 5029 \\ \hline
		21 & 2133 & 46 & 47881 & 71 & 25199 & 96 & 9433 \\ \hline
		22 & 3270 & 47 & 15273 & 72 & 21981 & 97 & 38202 \\ \hline
		23 & 27499 & 48 & 1346 & 73 & 48131 & 98 & 33052 \\ \hline
		24 & 33954 & 49 & 11422 & 74 & 13900 & 99 & 24332 \\ \hline
		25 & 17943 & 50 & 11215 & 75 & 6764 & 100 & 5224 \\ \hline
	\end{tabular}
	\label{tab:source}
\end{table}



\end{document}

